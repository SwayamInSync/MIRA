{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os.path\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T12:44:10.073330Z",
     "start_time": "2023-12-29T12:44:10.069529Z"
    }
   },
   "id": "547b03cba5ce4680"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.5774, 0.5774, 0.5774])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_at = torch.tensor([0, 0, 0], dtype=torch.float32)\n",
    "camera_position = torch.tensor([2, 2, 2], dtype=torch.float32)\n",
    "z_axis = camera_position - look_at\n",
    "z_axis = z_axis / torch.norm(z_axis)\n",
    "z_axis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:37:46.630194Z",
     "start_time": "2023-12-30T13:37:46.534629Z"
    }
   },
   "id": "67e0925fc817577e"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.7071,  0.7071,  0.0000])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_world = torch.tensor([0, 0, 1], dtype=torch.float32)\n",
    "x_axis = torch.cross(up_world, z_axis)\n",
    "x_axis = x_axis / torch.norm(x_axis)\n",
    "x_axis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:38:31.207707Z",
     "start_time": "2023-12-30T13:38:31.192557Z"
    }
   },
   "id": "edf7f0901a2f42a5"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.4082, -0.4082,  0.8165])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_axis = torch.cross(z_axis, x_axis)\n",
    "y_axis = y_axis / torch.norm(y_axis)\n",
    "y_axis"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:38:43.634086Z",
     "start_time": "2023-12-30T13:38:43.622516Z"
    }
   },
   "id": "15d7c54d3205136f"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7071, -0.4082,  0.5774,  2.0000],\n        [ 0.7071, -0.4082,  0.5774,  2.0000],\n        [ 0.0000,  0.8165,  0.5774,  2.0000]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extrinsic_matrix = torch.stack([x_axis, y_axis, z_axis, camera_position], dim=-1)\n",
    "extrinsic_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:38:49.622485Z",
     "start_time": "2023-12-30T13:38:49.615996Z"
    }
   },
   "id": "c83094d8462f4ec7"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "world_point = torch.tensor([1, 1, 1, 1], dtype=torch.float32)  # Homogeneous coordinates"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:39:24.725217Z",
     "start_time": "2023-12-30T13:39:24.721470Z"
    }
   },
   "id": "3e2a7bc8a27a4dcc"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7071,  0.7071,  0.0000,  0.0000],\n        [-0.4082, -0.4082,  0.8165,  0.0000],\n        [ 0.5774,  0.5774,  0.5774, -3.4641],\n        [ 0.0000,  0.0000,  0.0000,  1.0000]])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_matrix = extrinsic_matrix[:3, :3]\n",
    "translation_vector = extrinsic_matrix[:3, 3]\n",
    "inverse_rotation = rotation_matrix.T  # Transpose of the rotation matrix\n",
    "inverse_translation = -inverse_rotation @ translation_vector\n",
    "\n",
    "inverse_extrinsic = torch.eye(4)\n",
    "inverse_extrinsic[:3, :3] = inverse_rotation\n",
    "inverse_extrinsic[:3, 3] = inverse_translation\n",
    "inverse_extrinsic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:44:43.407588Z",
     "start_time": "2023-12-30T13:44:43.384773Z"
    }
   },
   "id": "8152bcafdbc118c0"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.0000,  0.0000, -1.7321,  1.0000])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_point = inverse_extrinsic @ world_point\n",
    "camera_point"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:40:11.215090Z",
     "start_time": "2023-12-30T13:40:11.210226Z"
    }
   },
   "id": "8c06ca15f15035f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4x4 RT matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b67007ebf65a088c"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.7071, -0.4082,  0.5774,  2.0000],\n        [ 0.7071, -0.4082,  0.5774,  2.0000],\n        [ 0.0000,  0.8165,  0.5774,  2.0000],\n        [ 0.0000,  0.0000,  0.0000,  1.0000]], dtype=torch.float64)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RT_matrix_4x4 = np.eye(4)\n",
    "RT_matrix_4x4[:3, :3] = rotation_matrix\n",
    "RT_matrix_4x4[:3, 3] = translation_vector\n",
    "\n",
    "torch.tensor(RT_matrix_4x4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:43:16.269879Z",
     "start_time": "2023-12-30T13:43:16.254491Z"
    }
   },
   "id": "6c44fbe80f29be21"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0000, 1.0000, 1.0000, 1.0000], dtype=torch.float64)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(RT_matrix_4x4) @ camera_point.to(dtype=torch.double)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T13:47:02.179451Z",
     "start_time": "2023-12-30T13:47:02.166226Z"
    }
   },
   "id": "44c76d2a401f0b66"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T04:35:05.030721Z",
     "start_time": "2023-12-31T04:35:05.030351Z"
    }
   },
   "id": "5e98672d3cef2fcb"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[384., 384.],\n        [256., 256.],\n        [512., 512.]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx = fy = 384\n",
    "cx = cy = 256\n",
    "w = h = 512\n",
    "intrinsics = torch.tensor([\n",
    "    [fx, fy],\n",
    "    [cx, cy],\n",
    "    [w, h],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "intrinsics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T04:53:32.216728Z",
     "start_time": "2023-12-31T04:53:32.211533Z"
    }
   },
   "id": "4a8e744afae3a150"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def get_normalized_camera_intrinsics(intrinsics: torch.Tensor):\n",
    "    \"\"\"\n",
    "    intrinsics: (N, 3, 2), [[fx, fy], [cx, cy], [width, height]]\n",
    "    Return batched fx, fy, cx, cy\n",
    "    \"\"\"\n",
    "    fx, fy = intrinsics[:, 0, 0], intrinsics[:, 0, 1]\n",
    "    cx, cy = intrinsics[:, 1, 0], intrinsics[:, 1, 1]\n",
    "    width, height = intrinsics[:, 2, 0], intrinsics[:, 2, 1]\n",
    "    fx, fy = fx / width, fy / height\n",
    "    cx, cy = cx / width, cy / height\n",
    "    return fx, fy, cx, cy\n",
    "\n",
    "\n",
    "def build_camera_principle(RT: torch.Tensor, intrinsics: torch.Tensor):\n",
    "    \"\"\"\n",
    "    RT: (N, 3, 4)\n",
    "    intrinsics: (N, 3, 2), [[fx, fy], [cx, cy], [width, height]]\n",
    "    \"\"\"\n",
    "    fx, fy, cx, cy = get_normalized_camera_intrinsics(intrinsics)\n",
    "    print(fx, fy, cx, cy)\n",
    "    return torch.cat([\n",
    "        RT.reshape(-1, 12),\n",
    "        fx.unsqueeze(-1), fy.unsqueeze(-1), cx.unsqueeze(-1), cy.unsqueeze(-1),\n",
    "    ], dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T04:49:19.760093Z",
     "start_time": "2023-12-31T04:49:19.753981Z"
    }
   },
   "id": "7945134604b15736"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7500]) tensor([0.7500]) tensor([0.5000]) tensor([0.5000])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([1, 16])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_to_center = 2\n",
    "canonical_camera_extrinsics = torch.tensor([[\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, -1, -dist_to_center],\n",
    "    [0, 1, 0, 0],\n",
    "]], dtype=torch.float32)\n",
    "canonical_camera_intrinsics = intrinsics.unsqueeze(0)\n",
    "source_camera = build_camera_principle(canonical_camera_extrinsics, canonical_camera_intrinsics)\n",
    "source_camera.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T04:49:55.774004Z",
     "start_time": "2023-12-31T04:49:55.750827Z"
    }
   },
   "id": "5cdeab36056c5cf6"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def center_looking_at_camera_pose(camera_position: torch.Tensor, look_at: torch.Tensor = None, up_world: torch.Tensor = None):\n",
    "    \"\"\"\n",
    "    camera_position: (M, 3)\n",
    "    look_at: (3)\n",
    "    up_world: (3)\n",
    "    return: (M, 3, 4)\n",
    "    \"\"\"\n",
    "    # by default, looking at the origin and world up is pos-z\n",
    "    if look_at is None:\n",
    "        look_at = torch.tensor([0, 0, 0], dtype=torch.float32)  # object is  at origin\n",
    "    if up_world is None:\n",
    "        up_world = torch.tensor([0, 0, 1], dtype=torch.float32)  # z-axis is upwards\n",
    "    look_at = look_at.unsqueeze(0).repeat(camera_position.shape[0], 1)\n",
    "    up_world = up_world.unsqueeze(0).repeat(camera_position.shape[0], 1)\n",
    "\n",
    "    z_axis = camera_position - look_at\n",
    "    z_axis = z_axis / z_axis.norm(dim=-1, keepdim=True)\n",
    "    x_axis = torch.cross(up_world, z_axis)\n",
    "    x_axis = x_axis / x_axis.norm(dim=-1, keepdim=True)\n",
    "    y_axis = torch.cross(z_axis, x_axis)\n",
    "    y_axis = y_axis / y_axis.norm(dim=-1, keepdim=True)\n",
    "    extrinsics = torch.stack([x_axis, y_axis, z_axis, camera_position], dim=-1)\n",
    "    return extrinsics\n",
    "\n",
    "def _get_surrounding_views(M: int = 2, radius: float = 2.0, height: float = 0.8):\n",
    "    # M: number of surrounding views\n",
    "    # radius: camera dist to center\n",
    "    # height: height of the camera\n",
    "    # return: (M, 3, 4)\n",
    "    assert M > 0\n",
    "    assert radius > 0\n",
    "\n",
    "    camera_positions = []\n",
    "    projected_radius = math.sqrt(radius ** 2 - height ** 2)\n",
    "    for i in range(M):\n",
    "        theta = 2 * math.pi * i / M - math.pi / 2  # starting point is top (y-axis)\n",
    "        x = projected_radius * math.cos(theta)\n",
    "        y = projected_radius * math.sin(theta)\n",
    "        z = height\n",
    "        camera_positions.append([x, y, z])\n",
    "    camera_positions = torch.tensor(camera_positions, dtype=torch.float32)\n",
    "    extrinsics = center_looking_at_camera_pose(camera_positions)\n",
    "    return extrinsics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T04:58:41.988750Z",
     "start_time": "2023-12-31T04:58:41.985682Z"
    }
   },
   "id": "8e907761d970b94b"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 4])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_camera_extrinsics = _get_surrounding_views()\n",
    "render_camera_intrinsics = intrinsics.unsqueeze(0).repeat(render_camera_extrinsics.shape[0], 1, 1)\n",
    "render_camera_extrinsics.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T04:58:42.244797Z",
     "start_time": "2023-12-31T04:58:42.238483Z"
    }
   },
   "id": "fab9f0ef447509af"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 1.0000e+00, -2.4493e-17,  5.6120e-17,  1.1224e-16],\n         [ 6.1232e-17,  4.0000e-01, -9.1652e-01, -1.8330e+00],\n         [-0.0000e+00,  9.1652e-01,  4.0000e-01,  8.0000e-01]]),\n tensor([[384., 384.],\n         [256., 256.],\n         [512., 512.]]))"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_camera_extrinsics[0], render_camera_intrinsics[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T04:59:26.840835Z",
     "start_time": "2023-12-31T04:59:26.832023Z"
    }
   },
   "id": "831d45b8de935a0f"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0000e+00, -2.4493e-17,  5.6120e-17,  1.1224e-16],\n",
      "         [ 6.1232e-17,  4.0000e-01, -9.1652e-01, -1.8330e+00],\n",
      "         [-0.0000e+00,  9.1652e-01,  4.0000e-01,  8.0000e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
      "\n",
      "        [[-1.0000e+00, -2.4493e-17,  5.6120e-17,  1.1224e-16],\n",
      "         [ 6.1232e-17, -4.0000e-01,  9.1652e-01,  1.8330e+00],\n",
      "         [ 0.0000e+00,  9.1652e-01,  4.0000e-01,  8.0000e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([2, 25])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compose_extrinsic_RT(RT: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compose the standard form extrinsic matrix from RT.\n",
    "    Batched I/O.\n",
    "    \"\"\"\n",
    "    return torch.cat([\n",
    "        RT,\n",
    "        torch.tensor([[[0, 0, 0, 1]]], dtype=torch.float32).repeat(RT.shape[0], 1, 1)\n",
    "        ], dim=1)\n",
    "\n",
    "\n",
    "E = compose_extrinsic_RT(render_camera_extrinsics)\n",
    "print(E)\n",
    "fx, fy, cx, cy = get_normalized_camera_intrinsics(render_camera_intrinsics)\n",
    "I = torch.stack([\n",
    "    torch.stack([fx, torch.zeros_like(fx), cx], dim=-1),\n",
    "    torch.stack([torch.zeros_like(fy), fy, cy], dim=-1),\n",
    "    torch.tensor([[0, 0, 1]], dtype=torch.float32, device=render_camera_extrinsics.device).repeat(render_camera_extrinsics.shape[0], 1),\n",
    "], dim=1)\n",
    "torch.cat([\n",
    "    E.reshape(-1, 16),\n",
    "    I.reshape(-1, 9),\n",
    "], dim=-1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T05:54:53.933053Z",
     "start_time": "2023-12-31T05:54:53.822347Z"
    }
   },
   "id": "f91061ec76bda210"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Rendering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a469fc8ed21b174"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 4)"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam = np.load(\"temp_data/render/000.npy\")\n",
    "cam.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T16:55:11.629592Z",
     "start_time": "2023-12-31T16:55:11.610833Z"
    }
   },
   "id": "6546c80d09a81b26"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-8.42718780e-01,  5.38353980e-01,  3.31587557e-09,\n        -8.96162987e-02],\n       [ 5.95299751e-02,  9.31859463e-02,  9.93867457e-01,\n         7.56601989e-03],\n       [ 5.35052538e-01,  8.37550759e-01, -1.10577732e-01,\n        -2.07504749e+00]])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T17:06:26.145281Z",
     "start_time": "2023-12-31T17:06:26.123204Z"
    }
   },
   "id": "eaf86cee90f211b6"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-8.42718780e-01,  5.38353980e-01,  3.31587557e-09,\n        -8.96162987e-02],\n       [ 5.95299751e-02,  9.31859463e-02,  9.93867457e-01,\n         7.56601989e-03],\n       [ 5.35052538e-01,  8.37550759e-01, -1.10577732e-01,\n        -2.07504749e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00]])"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([cam, np.array([0, 0, 0, 1], dtype=np.float64)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T17:13:55.291659Z",
     "start_time": "2023-12-31T17:13:55.291038Z"
    }
   },
   "id": "290a32f5cdc879c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2112c5ba19ded29"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(267.0834), tensor(98.0923))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(3,3)*275\n",
    "a.max(), a.min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T09:10:08.564152Z",
     "start_time": "2024-02-19T09:10:08.554695Z"
    }
   },
   "id": "9574e0a333de6ccd"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(1024, 1024, 3)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "cv.imread(\"temp_data/render/impeller/000.png\").shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:43:17.271165Z",
     "start_time": "2024-02-19T11:43:17.235967Z"
    }
   },
   "id": "b931536d2a45718b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4a00e48fb2a7c12f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
